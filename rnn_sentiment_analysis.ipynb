{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9tkYmTmovyE"
      },
      "source": [
        "# Analysis of the tone of reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeNU36VQpCNc"
      },
      "source": [
        "Задача - классифицировать отзывы с IMDB на положительный / отрицательный только по тексту."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N3D2XDBpHVh"
      },
      "source": [
        "<img src=\"https://github.com/bentrevett/pytorch-sentiment-analysis/raw/bf8cc46e4823ebf9af721b595501ad6231c73632/assets/sentiment1.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXo1b3E0rMdk"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0vhMRG-pOQc",
        "outputId": "b2f1dcb0-575c-4474-e384-e25d1355b043"
      },
      "source": [
        "!pip install torchtext\n",
        "!python -m spacy download en"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchtext) (3.10.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPO9D03lpRWx"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize='spacy')\n",
        "LABEL = data.LabelField()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ER7M5b0pTge",
        "outputId": "9e43f7cc-e7cd-4ad0-81d9-0c2189579d61"
      },
      "source": [
        "from torchtext.legacy import datasets\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL, root=\"./data\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 84.1M/84.1M [00:02<00:00, 40.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjqd-eFypUwv",
        "outputId": "72c31df8-80ba-4319-e10a-3a7e76a07af5"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJxq0yLupY0d",
        "outputId": "1dc15f46-d000-4fd2-961a-cb978b262960"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['I', 'found', 'the', 'film', 'quite', 'expressive', ',', 'the', 'way', 'the', 'main', 'character', 'was', 'lost', 'but', 'at', 'the', 'same', 'much', 'more', 'clear', 'about', 'certain', 'things', 'in', 'life', 'than', 'people', 'who', 'mocked', 'him', '(', 'his', 'flatmate', 'for', 'example', ')', '.<br', '/><br', '/>he', 'was', 'tortured', 'and', 'you', 'loved', 'to', 'watch', 'him', 'being', 'tortured', '!', 'it', 'had', 'this', 'perverted', 'side', 'which', 'was', 'frightening', 'but', 'we', 'were', 'all', 'happy', 'to', 'see', 'him', 'come', 'out', 'of', 'the', 'misery', 'again', '.<br', '/><br', '/>it', 'was', 'like', 'a', 'game', 'character', 'or', 'pan', '-', 'man', 'through', 'a', 'mine', '-', 'land', 'or', 'to', 'enemy', 'and', 'we', 'love', 'to', 'watch', 'him', 'under', 'sniper', 'attack', 'or', 'fire', 'but', 'then', 'at', 'the', 'end', 'we', 'are', 'happy', 'to', 'see', 'him', 'survive', '...', '<', 'br', '/><br', '/', '>', '.'], 'label': 'pos'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEMgntY0pbM0"
      },
      "source": [
        "import random\n",
        "\n",
        "test_data, valid_data = test_data.split(random_state=random.seed(SEED), split_ratio=0.5)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBmgsKATpdhK"
      },
      "source": [
        "TEXT.build_vocab(train_data, max_size=25000)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0jo0isvpflI",
        "outputId": "c079b9d7-e259-4d73-9d71-393359d81be0"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta0RMZlLphei",
        "outputId": "2b331b66-63d9-47fc-ab00-3a1967bc496c"
      },
      "source": [
        "vars(LABEL.vocab)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'freqs': Counter({'neg': 12500, 'pos': 12500}),\n",
              " 'itos': ['neg', 'pos'],\n",
              " 'stoi': defaultdict(None, {'neg': 0, 'pos': 1}),\n",
              " 'unk_index': None,\n",
              " 'vectors': None}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdNlekDdpl7l",
        "outputId": "f1909d05-ed8f-4242-fa51-18d800b3e214"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 289838), (',', 275296), ('.', 236843), ('and', 156483), ('a', 156282), ('of', 144055), ('to', 133886), ('is', 109095), ('in', 87676), ('I', 77546), ('it', 76545), ('that', 70355), ('\"', 63329), (\"'s\", 61928), ('this', 60483), ('-', 52863), ('/><br', 50935), ('was', 50013), ('as', 43508), ('with', 42807)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovIDwwdOppfZ"
      },
      "source": [
        "* stoi (string to int)\n",
        "* itos (int to string)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTlYymmgpqMk",
        "outputId": "be1e2164-b65c-477c-c06b-55adf3da49fa"
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAVvdcWnptYN",
        "outputId": "833db205-62b2-4a40-b6a2-96af69b1a763"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(None, {'neg': 0, 'pos': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nkDoWuapwE7"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device,\n",
        "    sort=True,\n",
        "    sort_key=lambda x: len(x.text),\n",
        "    repeat=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw3qFiEYpzzw"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsOXtGkyolNr"
      },
      "source": [
        "<img src=\"https://github.com/bentrevett/pytorch-sentiment-analysis/raw/bf8cc46e4823ebf9af721b595501ad6231c73632/assets/sentiment7.png\" width=\"450\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KwHKZ0Np94L"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        output, hidden = self.rnn(embedded)\n",
        "\n",
        "        return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evL5GUscqBfy"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "INPUT_DIM = len(TEXT.vocab.stoi)\n",
        "EMBEDDING_DIM = 256\n",
        "HIDDEN_DIM = 64\n",
        "OUTPUT_DIM = 2\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
        "\n",
        "def get_accuracy(logit, target, batch_size):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
        "    accuracy = 100.0 * corrects/batch_size\n",
        "    return accuracy.item()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM8DgMcxqDbj"
      },
      "source": [
        "def train_func(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.text)\n",
        "\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = get_accuracy(predictions, batch.label, BATCH_SIZE)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss\n",
        "        epoch_acc += acc\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4kUxRrXqIND"
      },
      "source": [
        "def evaluate_func(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.text)\n",
        "\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = get_accuracy(predictions, batch.label, BATCH_SIZE)\n",
        "\n",
        "            epoch_loss += loss\n",
        "            epoch_acc += acc\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83kZYcJPqJN0",
        "outputId": "37a1e042-a5e7-43c0-f4ae-436ce785dfba"
      },
      "source": [
        "N_EPOCHS = 15\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss, train_acc = train_func(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate_func(model, valid_iterator, criterion)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%, Val. Loss: {valid_loss:.3f}, Val. Acc: {valid_acc:.2f}%')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Train Loss: 0.654, Train Acc: 61.01%, Val. Loss: 0.704, Val. Acc: 50.75%\n",
            "Epoch: 02, Train Loss: 0.641, Train Acc: 62.49%, Val. Loss: 0.706, Val. Acc: 50.62%\n",
            "Epoch: 03, Train Loss: 0.637, Train Acc: 62.80%, Val. Loss: 0.705, Val. Acc: 50.61%\n",
            "Epoch: 04, Train Loss: 0.633, Train Acc: 62.99%, Val. Loss: 0.702, Val. Acc: 50.80%\n",
            "Epoch: 05, Train Loss: 0.620, Train Acc: 65.08%, Val. Loss: 0.680, Val. Acc: 57.22%\n",
            "Epoch: 06, Train Loss: 0.577, Train Acc: 69.58%, Val. Loss: 0.682, Val. Acc: 61.83%\n",
            "Epoch: 07, Train Loss: 0.545, Train Acc: 72.23%, Val. Loss: 0.737, Val. Acc: 60.57%\n",
            "Epoch: 08, Train Loss: 0.554, Train Acc: 72.08%, Val. Loss: 0.614, Val. Acc: 68.74%\n",
            "Epoch: 09, Train Loss: 0.494, Train Acc: 76.70%, Val. Loss: 0.659, Val. Acc: 62.53%\n",
            "Epoch: 10, Train Loss: 0.468, Train Acc: 78.16%, Val. Loss: 0.583, Val. Acc: 71.72%\n",
            "Epoch: 11, Train Loss: 0.430, Train Acc: 81.07%, Val. Loss: 0.561, Val. Acc: 74.12%\n",
            "Epoch: 12, Train Loss: 0.428, Train Acc: 81.72%, Val. Loss: 0.658, Val. Acc: 68.52%\n",
            "Epoch: 13, Train Loss: 0.393, Train Acc: 83.30%, Val. Loss: 0.552, Val. Acc: 74.77%\n",
            "Epoch: 14, Train Loss: 0.366, Train Acc: 85.04%, Val. Loss: 0.577, Val. Acc: 76.20%\n",
            "Epoch: 15, Train Loss: 0.353, Train Acc: 85.98%, Val. Loss: 0.544, Val. Acc: 76.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahymGBktqM18",
        "outputId": "21d56fab-63b6-4350-919e-80ea342bdd63"
      },
      "source": [
        "test_loss , test_acc = evaluate_func(model, test_iterator, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}%')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.537, Test Acc: 76.61%\n"
          ]
        }
      ]
    }
  ]
}